# -*- coding: utf-8 -*-
"""machine_learning_VazquezGarcia_Carmen.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1N91iFqoiF4s6d8lN8eLfDfsAhXlQBR9o

#Tarea del Tema 7:

Estudiante: Carmen Vázquez García

**Se ha decidido realizar la práctica en Google Colab, donde se han dejado comentarios del proceso y un análisis de los resultados obtenidos.**

En esta práctica se lleva a cabo el proceso completo de preprocesamiento, partición, y análisis de un conjunto de documentos utilizando herramientas de procesamiento de lenguaje natural (NLP) y aprendizaje automático. A continuación se describen las etapas y logros clave de la práctica:

1. **Conexión con Google Drive**
*   Se monta Google Drive para acceder a los archivos de datos almacenados.
*   Definición de rutas y parámetros: Se especifica la ruta de la carpeta con los documentos y el porcentaje de documentos para el conjunto de entrenamiento (70 %) y para el conjunto de prueba (30 %).

2. **Partición de datos**
*   Listado y partición de archivos: Se listan los archivos en la carpeta especificada, se calculan cuántos archivos irán al conjunto de entrenamiento y prueba, y se mezclan aleatoriamente.
*   Creación de directorios: Se crean directorios separados para los archivos de entrenamiento y prueba.
*   Copia de archivos: Se copian los archivos correspondientes a cada directorio (entrenamiento y prueba).
*   Creación de archivos de lista: Se crean archivos de texto (train_set.txt y test_set.txt) que contienen los nombres de los archivos de entrenamiento y prueba.

3. **Lectura y almacenamiento de los conjuntos:**
*   Se leen y almacenan los contenidos de los archivos HTML en listas separadas para los conjuntos de entrenamiento y prueba.

4. **Preprocesamiento de texto:**
*   Extracción de texto con BeautifulSoup: Se extrae el texto de las etiquetas <html> de los archivos HTML utilizando BeautifulSoup.
*   Tokenización y limpieza: Se tokeniza el texto, eliminan las palabras vacías y los signos de puntuación, y se aplica stemming para obtener la raíz de las palabras.

5. **Asignación de etiquetas:**
*   Etiquetado de documentos: Se asignan etiquetas a los documentos en función de la primera letra del nombre del archivo.

6. **Representación de texto (TF-IDF y promedio [*average model*]):**
*   TF-IDF: Se utiliza TfidfVectorizer para transformar los
documentos en representaciones TF-IDF.
*   Vectorización de conteo: Se usa CountVectorizer para representar los documentos en base a la frecuencia de términos.
*   Entrenamiento de Word2Vec: Se entrena un modelo Word2Vec con el conjunto de entrenamiento para obtener representaciones vectoriales de las palabras.
*   Cálculo de vectores promedio: Se calculan las representaciones promedio de los documentos utilizando los vectores de Word2Vec.

7. **Entrenamiento y evaluación de modelos**
*   Naïve Bayes con CountVectorizer: Se entrena un modelo Naive Bayes con las representaciones de CountVectorizer y se evalúa en el conjunto de prueba.
*   Naïve Bayes con Word2Vec: Se entrena y evalúa un modelo Naïve Bayes con las representaciones promedio de los documentos.
*   Matriz de confusión y métricas: Se calcula y visualiza la matriz de confusión y se reportan métricas de precisión y F1.

8. **Resultados y visualización**
*   Visualización de la matriz de confusión: Se visualiza la matriz de confusión para analizar los errores de clasificación.
*   Métricas finales: Se calculan y reportan las métricas finales de precisión y F1 para evaluar el rendimiento del modelo.

9. **Comentarios de resultados**
"""

import os
import random
from shutil import copyfile

# Mediante estos comandos podemos enlazar nuestro notebook en Colab con nuestro almacenamiento en Google Drive
from google.colab import drive
drive.mount('/content/drive/')

# Ruta de la carpeta en Google Drive
folder_path = "/content/drive/MyDrive/BankSearch-reduced"

# Porcentaje de documentos para training set
train_percentage = 0.7

# Listar archivos en la carpeta
files = os.listdir(folder_path)

# Calcular cuántos documentos tomar para training set
num_train_files = int(len(files) * train_percentage)

# Mezclar aleatoriamente los nombres de los archivos
random.shuffle(files)

# Dividir la lista de archivos en training set y test set
train_files = files[:num_train_files]
test_files = files[num_train_files:]

# Crear directorios para training set y test set
train_dir = "train"
test_dir = "test"
os.makedirs(train_dir, exist_ok=True)
os.makedirs(test_dir, exist_ok=True)

# Mover los archivos correspondientes a training set
for file_name in train_files:
    src = os.path.join(folder_path, file_name)
    dst = os.path.join(train_dir, file_name)
    copyfile(src, dst)

# Mover los archivos correspondientes a test set
for file_name in test_files:
    src = os.path.join(folder_path, file_name)
    dst = os.path.join(test_dir, file_name)
    copyfile(src, dst)

print("Se ha completado la división de los documentos en training set y test set.")

# Nombre de los archivos que almacenarán la lista de archivos para training set y test set
train_set_file = "train_set.txt"
test_set_file = "test_set.txt"

train_set_file = "/content/drive/MyDrive/train_set.txt"
test_set_file = "/content/drive/MyDrive/test_set.txt"

# Escribir los nombres de los archivos para training set en train_set.txt
with open(train_set_file, 'w') as train_file:
    for file_name in train_files:
        train_file.write(file_name + '\n')

# Escribir los nombres de los archivos para test set en test_set.txt
with open(test_set_file, 'w') as test_file:
    for file_name in test_files:
        test_file.write(file_name + '\n')

print("Se han creado los archivos train_set.txt y test_set.txt con los nombres de los archivos para training set y test set respectivamente.")

# Rutas de los archivos de los conjuntos de entrenamiento y prueba
train_set_file = "/content/drive/MyDrive/train_set.txt"
test_set_file = "/content/drive/MyDrive/test_set.txt"

# Leer los nombres de los archivos del conjunto de entrenamiento
with open(train_set_file, 'r') as train_file:
    train_files = train_file.readlines()

# Leer los nombres de los archivos del conjunto de prueba
with open(test_set_file, 'r') as test_file:
    test_files = test_file.readlines()

# Imprimir las primeras 15 líneas de cada conjunto de datos
print("Primeras 15 líneas del conjunto de entrenamiento:")
print(train_files[:15])

print("\nPrimeras 15 líneas del conjunto de prueba:")
print(test_files[:15])

import os

# Función para leer el contenido de un archivo dado su nombre
def read_file_content(file_name):
    with open(os.path.join(folder_path, file_name), 'r', encoding='latin1') as file:
        content = file.read()
    return content

# Leer y almacenar el contenido de cada archivo en el conjunto de entrenamiento
training_set = []
for file_name in train_files:
    file_content = read_file_content(file_name.strip())
    training_set.append(file_content)

# Leer y almacenar el contenido de cada archivo en el conjunto de prueba
test_set = []
for file_name in test_files:
    file_content = read_file_content(file_name.strip())
    test_set.append(file_content)

# Imprimir las primeras 15 líneas de cada conjunto de datos
print("Primeras 15 líneas del conjunto de entrenamiento:")
for i, content in enumerate(training_set[:15], 1):
    print(f"Documento {i}:")
    print(content[:50])  # Imprimir los primeros 50 caracteres del contenido

print("\nPrimeras 15 líneas del conjunto de prueba:")
for i, content in enumerate(test_set[:15], 1):
    print(f"Documento {i}:")
    print(content[:50])  # Imprimir los primeros 50 caracteres del contenido

import os
from bs4 import BeautifulSoup

# Función para leer y extraer el contenido de un archivo HTML dado su nombre
def read_html_content(file_name):
    with open(os.path.join(folder_path, file_name), 'r', encoding='latin1') as file:
        html_content = file.read()
        # Utilizar BeautifulSoup para analizar el HTML
        soup = BeautifulSoup(html_content, 'html.parser')
        # Encontrar la etiqueta <html>
        html_tag = soup.find('html')
        if html_tag:
            # Si se encuentra la etiqueta <html>, extraer su texto
            text_content = html_tag.get_text().strip()  # Eliminar espacios en blanco adicionales al principio y al final
        else:
            # Si la etiqueta <html> no se encuentra, establecer el contenido como vacío
            text_content = ''
    return text_content

# Leer y almacenar el contenido de cada archivo HTML en el conjunto de entrenamiento
training_set = []
for file_name in train_files:
    file_content = read_html_content(file_name.strip())
    training_set.append(file_content)

# Leer y almacenar el contenido de cada archivo HTML en el conjunto de prueba
test_set = []
for file_name in test_files:
    file_content = read_html_content(file_name.strip())
    test_set.append(file_content)

# Imprimir las primeras 15 líneas de cada conjunto de datos (opcional)
print("Primeras 15 líneas del conjunto de entrenamiento:")
for i, content in enumerate(training_set[:15], 1):
    print(f"Documento {i}:")
    # Eliminar espacios en blanco adicionales y saltos de línea adicionales antes de imprimir
    content_cleaned = ' '.join(content.split())
    print(content_cleaned[:50])  # Imprimir los primeros 50 caracteres del contenido

print("\nPrimeras 15 líneas del conjunto de prueba:")
for i, content in enumerate(test_set[:15], 1):
    print(f"Documento {i}:")
    # Eliminar espacios en blanco adicionales y saltos de línea adicionales antes de imprimir
    content_cleaned = ' '.join(content.split())
    print(content_cleaned[:50])  # Imprimir los primeros 50 caracteres del contenido

import os
import re
import nltk
from nltk.corpus import stopwords
from nltk.stem import SnowballStemmer
from bs4 import BeautifulSoup

# Descargar recursos adicionales de NLTK
nltk.download('punkt')
nltk.download('stopwords')

# Función para leer y preprocesar el contenido de un archivo HTML dado su nombre
def preprocess_html_content(file_name):
    with open(os.path.join(folder_path, file_name), 'r', encoding='latin1') as file:
        html_content = file.read()
        # Utilizar BeautifulSoup para analizar el HTML
        soup = BeautifulSoup(html_content, 'html.parser')
        # Encontrar la etiqueta <html>
        html_tag = soup.find('html')
        if html_tag:
            # Si se encuentra la etiqueta <html>, extraer su texto
            text_content = html_tag.get_text().strip()  # Eliminar espacios en blanco adicionales al principio y al final
            # Realizar tokenización
            tokens = nltk.word_tokenize(text_content)
            # Eliminar stopwords y signos de puntuación
            stop_words = set(stopwords.words('english'))
            filtered_tokens = [word.lower() for word in tokens if word.isalnum() and word.lower() not in stop_words]
            # Realizar stemming
            stemmer = SnowballStemmer('english')
            stemmed_tokens = [stemmer.stem(token) for token in filtered_tokens]
            # Unir los tokens preprocesados en un texto limpio
            preprocessed_text = ' '.join(stemmed_tokens)
        else:
            # Si la etiqueta <html> no se encuentra, establecer el contenido como vacío
            preprocessed_text = ''
    return preprocessed_text

# Leer y preprocesar el contenido de cada archivo HTML en el conjunto de entrenamiento
training_set = []
for file_name in train_files:
    file_content = preprocess_html_content(file_name.strip())
    training_set.append(file_content)

# Leer y preprocesar el contenido de cada archivo HTML en el conjunto de prueba
test_set = []
for file_name in test_files:
    file_content = preprocess_html_content(file_name.strip())
    test_set.append(file_content)

# Imprimir las primeras 15 líneas de cada conjunto de datos preprocesado (opcional)
print("Primeras 15 líneas del conjunto de entrenamiento preprocesado:")
for content in training_set[:15]:
    print(content[:100])  # Imprimir los primeros 500 caracteres del contenido

print("\nPrimeras 15 líneas del conjunto de prueba preprocesado:")
for content in test_set[:15]:
    print(content[:100])  # Imprimir los primeros 500 caracteres del contenido

import os

# Función para obtener la etiqueta de un nombre de archivo
def get_label(file_name):
    # La etiqueta es la primera letra del nombre de archivo
    return file_name[0]

# Lista para almacenar las etiquetas de los documentos de entrenamiento y prueba
train_labels = []
test_labels = []

# Asignar etiquetas a los documentos de entrenamiento
for file_name in train_files:
    label = get_label(file_name)
    train_labels.append(label)

# Asignar etiquetas a los documentos de prueba
for file_name in test_files:
    label = get_label(file_name)
    test_labels.append(label)

# Imprimir las etiquetas de ejemplo
print("Ejemplo de etiquetas del conjunto de entrenamiento:", train_labels[:10])
print("Ejemplo de etiquetas del conjunto de prueba:", test_labels[:10])
import os

# Función para obtener la etiqueta de un nombre de archivo
def get_label(file_name):
    # La etiqueta es la primera letra del nombre de archivo
    return file_name[0]

# Lista para almacenar las etiquetas de los documentos de entrenamiento y prueba
train_labels = []
test_labels = []

# Asignar etiquetas a los documentos de entrenamiento
for file_name in train_files:
    label = get_label(file_name)
    train_labels.append(label)

# Asignar etiquetas a los documentos de prueba
for file_name in test_files:
    label = get_label(file_name)
    test_labels.append(label)

# Imprimir las etiquetas de ejemplo
print("Ejemplo de etiquetas del conjunto de entrenamiento:", train_labels[:10])
print("Ejemplo de etiquetas del conjunto de prueba:", test_labels[:10])

"""#Algoritmo escogido: Naïve Bayes

Naive Bayes es un algoritmo de clasificación probabilístico que se basa en el teorema de Bayes para realizar predicciones. La principal suposición detrás de Naive Bayes es que todas las características son independientes entre sí, lo que significa que la presencia de una característica en una clase no está relacionada con la presencia de ninguna otra característica.

En el contexto de la clasificación de texto, Naive Bayes es comúnmente utilizado debido a su simplicidad y eficiencia. Sin embargo, existen diferentes variantes de Naive Bayes que se adaptan mejor a diferentes tipos de datos.

MultinomialNB: Esta variante es adecuada para datos discretos, como conteos de palabras o frecuencias de términos. Por lo tanto, es ampliamente utilizado en tareas de clasificación de texto donde las características son representadas por la frecuencia de ocurrencia de palabras en un documento. Por ejemplo, en análisis de sentimientos o clasificación de documentos por temas.

GaussianNB: En contraste, esta variante es más apropiada para datos continuos que siguen una distribución gaussiana, como vectores de características promedio generados por modelos de embedding de palabras como Word2Vec o GloVe. Este enfoque es útil cuando se trabaja con datos numéricos que representan características continuas, como la representación vectorial de palabras en un espacio semántico.

#Naïve Bayes con TF-IDF
"""

from sklearn.feature_extraction.text import TfidfVectorizer

# Crear un objeto TfidfVectorizer con el vocabulario del conjunto de entrenamiento
tfidf_vectorizer = TfidfVectorizer(vocabulary=None)

# Ajustar el TfidfVectorizer al conjunto de entrenamiento y transformar los conjuntos de entrenamiento y prueba
tfidf_train_representation = tfidf_vectorizer.fit_transform(training_set)
tfidf_test_representation = tfidf_vectorizer.transform(test_set)

# Imprimir la forma de las representaciones TF-IDF
print("Forma de la representación TF-IDF del conjunto de entrenamiento:", tfidf_train_representation.shape)
print("Forma de la representación TF-IDF del conjunto de prueba:", tfidf_test_representation.shape)

# Obtener los términos del vocabulario del TfidfVectorizer
vocabulario = tfidf_vectorizer.get_feature_names_out()

# Obtener los índices de los términos no cero en la representación TF-IDF del primer documento de entrenamiento
indices_no_cero = tfidf_train_representation[0].nonzero()[1]

# Obtener los términos y sus valores TF-IDF correspondientes para el primer documento de entrenamiento
terminos_valores = [(vocabulario[idx], tfidf_train_representation[0, idx]) for idx in indices_no_cero]

# Imprimir los primeros 100 términos y sus valores TF-IDF
print("Primeros 100 términos y valores TF-IDF del primer documento de entrenamiento:")
for i, (termino, valor) in enumerate(terminos_valores[:100], 1):
    print(f"{i}. Término: {termino}, Valor TF-IDF: {valor}")

from sklearn.feature_extraction.text import CountVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score
import matplotlib.pyplot as plt
import seaborn as sns

# Crear un objeto CountVectorizer con el vocabulario del conjunto de entrenamiento
count_vectorizer = CountVectorizer()

# Ajustar el CountVectorizer al conjunto de entrenamiento y transformar los conjuntos de entrenamiento y prueba
train_text_features = count_vectorizer.fit_transform(training_set)
test_text_features = count_vectorizer.transform(test_set)

# Entrenar el modelo Naive Bayes con las representaciones CountVectorizer del conjunto de entrenamiento
nb_classifier = MultinomialNB()
nb_classifier.fit(train_text_features, train_labels)

print("Predicting on the test set")
y_pred = nb_classifier.predict(test_text_features)

print("Classification Report")
print(classification_report(test_labels, y_pred, target_names=list("ABCDEFGHIJ")))

# Calcular la matriz de confusión
cm = confusion_matrix(test_labels, y_pred, labels=list("ABCDEFGHIJ"))

# Función para visualizar la matriz de confusión
def plot_confusion_matrix(cm, classes):
    plt.figure(figsize=(10, 7))
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=classes, yticklabels=classes)
    plt.xlabel('Predicted')
    plt.ylabel('True')
    plt.show()

plot_confusion_matrix(cm, classes=list("ABCDEFGHIJ"))

# Calcular y mostrar la precisión y la medida F1 del modelo
accuracy = accuracy_score(test_labels, y_pred)
f1 = f1_score(test_labels, y_pred, average='weighted')

print(f"Final Accuracy: {accuracy * 100:.2f}%")
print(f"Final F1 Score: {f1:.2f}")

from sklearn.feature_extraction.text import CountVectorizer
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score
import matplotlib.pyplot as plt
import seaborn as sns

# Crear un objeto CountVectorizer con el vocabulario del conjunto de entrenamiento
count_vectorizer = CountVectorizer()

# Ajustar el CountVectorizer al conjunto de entrenamiento y transformar los conjuntos de entrenamiento y prueba
train_text_features = count_vectorizer.fit_transform(training_set).toarray()
test_text_features = count_vectorizer.transform(test_set).toarray()

# Entrenar el modelo Gaussian Naive Bayes con las representaciones CountVectorizer del conjunto de entrenamiento
nb_classifier = GaussianNB()
nb_classifier.fit(train_text_features, train_labels)

print("Predicting on the test set")
y_pred = nb_classifier.predict(test_text_features)

print("Classification Report")
print(classification_report(test_labels, y_pred, target_names=list("ABCDEFGHIJ")))

# Calcular la matriz de confusión
cm = confusion_matrix(test_labels, y_pred, labels=list("ABCDEFGHIJ"))

# Función para visualizar la matriz de confusión
def plot_confusion_matrix(cm, classes):
    plt.figure(figsize=(10, 7))
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=classes, yticklabels=classes)
    plt.xlabel('Predicted')
    plt.ylabel('True')
    plt.show()

plot_confusion_matrix(cm, classes=list("ABCDEFGHIJ"))

# Calcular y mostrar la precisión y la medida F1 del modelo
accuracy = accuracy_score(test_labels, y_pred)
f1 = f1_score(test_labels, y_pred, average='weighted')

print(f"Final Accuracy: {accuracy * 100:.2f}%")
print(f"Final F1 Score: {f1:.2f}")

"""#Naïve Bayes con *average model*"""

from gensim.models import Word2Vec
import numpy as np

# Entrenar un modelo Word2Vec con el conjunto de entrenamiento preprocesado
word2vec_model = Word2Vec([document.split() for document in training_set], vector_size=100, window=5, min_count=1, sg=1)

# Función para calcular el vector promedio de un documento
def average_vector(document, model):
    vectors = [model.wv[word] for word in document.split() if word in model.wv]
    return np.mean(vectors, axis=0) if vectors else np.zeros(model.vector_size)

# Calcular la representación promedio para el conjunto de entrenamiento
avg_train_representation = np.array([average_vector(document, word2vec_model) for document in training_set])

# Calcular la representación promedio para el conjunto de prueba
avg_test_representation = np.array([average_vector(document, word2vec_model) for document in test_set])

# Imprimir la forma de las representaciones promedio
print("Forma de la representación promedio del conjunto de entrenamiento:", avg_train_representation.shape)
print("Forma de la representación promedio del conjunto de prueba:", avg_test_representation.shape)

# Imprimir la forma de las representaciones promedio
print("Forma de la representación promedio del conjunto de entrenamiento:", avg_train_representation.shape)
print("Forma de la representación promedio del conjunto de prueba:", avg_test_representation.shape)

# Imprimir algunas muestras de las representaciones promedio
print("\nAlgunas muestras de las representaciones promedio del conjunto de entrenamiento:")
for i in range(3):  # Imprimir las primeras 3 muestras
    print(f"Muestra {i+1}: {avg_train_representation[i]}")

print("\nAlgunas muestras de las representaciones promedio del conjunto de prueba:")
for i in range(3):  # Imprimir las primeras 3 muestras
    print(f"Muestra {i+1}: {avg_test_representation[i]}")

# Crear una lista de palabras únicas presentes en el conjunto de entrenamiento
unique_words = set()
for document in training_set:
    words = document.split()
    unique_words.update(words)

# Convertir la lista de palabras únicas a un vocabulario indexado
word2idx = {word: idx for idx, word in enumerate(unique_words)}

# Imprimir el tamaño del vocabulario
print("Tamaño del vocabulario:", len(word2idx))

from gensim.models import Word2Vec
import numpy as np
from sklearn.naive_bayes import MultinomialNB
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score
import matplotlib.pyplot as plt
import seaborn as sns

# Entrenar un modelo Word2Vec con el conjunto de entrenamiento preprocesado
word2vec_model = Word2Vec([document.split() for document in training_set], vector_size=100, window=5, min_count=1, sg=1)

# Función para calcular el vector promedio de un documento
def average_vector(document, model):
    vectors = [model.wv[word] for word in document.split() if word in model.wv]
    return np.mean(vectors, axis=0) if vectors else np.zeros(model.vector_size)

# Calcular la representación promedio para el conjunto de entrenamiento
avg_train_representation = np.array([average_vector(document, word2vec_model) for document in training_set])

# Calcular la representación promedio para el conjunto de prueba
avg_test_representation = np.array([average_vector(document, word2vec_model) for document in test_set])

# Imprimir la forma de las representaciones promedio
print("Forma de la representación promedio del conjunto de entrenamiento:", avg_train_representation.shape)
print("Forma de la representación promedio del conjunto de prueba:", avg_test_representation.shape)

# Normalizar los vectores para que no tengan valores negativos
scaler = MinMaxScaler()
avg_train_representation = scaler.fit_transform(avg_train_representation)
avg_test_representation = scaler.transform(avg_test_representation)

# Entrenar el modelo Naive Bayes con las representaciones promedio del conjunto de entrenamiento
nb_classifier = MultinomialNB()
nb_classifier.fit(avg_train_representation, train_labels)

print("Predicting on the test set")
y_pred = nb_classifier.predict(avg_test_representation)

print("Classification Report")
print(classification_report(test_labels, y_pred, target_names=list("ABCDEFGHIJ")))

# Calcular la matriz de confusión
cm = confusion_matrix(test_labels, y_pred, labels=list("ABCDEFGHIJ"))

# Función para visualizar la matriz de confusión
def plot_confusion_matrix(cm, classes):
    plt.figure(figsize=(10, 7))
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=classes, yticklabels=classes)
    plt.xlabel('Predicted')
    plt.ylabel('True')
    plt.show()

plot_confusion_matrix(cm, classes=list("ABCDEFGHIJ"))

# Calcular y mostrar la precisión y la medida F1 del modelo
accuracy = accuracy_score(test_labels, y_pred)
f1 = f1_score(test_labels, y_pred, average='weighted')

print(f"Final Accuracy: {accuracy * 100:.2f}%")
print(f"Final F1 Score: {f1:.2f}")

from gensim.models import Word2Vec
import numpy as np
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score
import matplotlib.pyplot as plt
import seaborn as sns

# Entrenar un modelo Word2Vec con el conjunto de entrenamiento preprocesado
word2vec_model = Word2Vec([document.split() for document in training_set], vector_size=100, window=5, min_count=1, sg=1)

# Función para calcular el vector promedio de un documento
def average_vector(document, model):
    vectors = [model.wv[word] for word in document.split() if word in model.wv]
    return np.mean(vectors, axis=0) if vectors else np.zeros(model.vector_size)

# Calcular la representación promedio para el conjunto de entrenamiento
avg_train_representation = np.array([average_vector(document, word2vec_model) for document in training_set])

# Calcular la representación promedio para el conjunto de prueba
avg_test_representation = np.array([average_vector(document, word2vec_model) for document in test_set])

# Imprimir la forma de las representaciones promedio
print("Forma de la representación promedio del conjunto de entrenamiento:", avg_train_representation.shape)
print("Forma de la representación promedio del conjunto de prueba:", avg_test_representation.shape)

# Entrenar el modelo Naive Bayes con las representaciones promedio del conjunto de entrenamiento
nb_classifier = GaussianNB()
nb_classifier.fit(avg_train_representation, train_labels)

print("Predicting on the test set")
y_pred = nb_classifier.predict(avg_test_representation)

print("Classification Report")
print(classification_report(test_labels, y_pred, target_names=list("ABCDEFGHIJ")))

# Calcular la matriz de confusión
cm = confusion_matrix(test_labels, y_pred, labels=list("ABCDEFGHIJ"))

# Función para visualizar la matriz de confusión
def plot_confusion_matrix(cm, classes):
    plt.figure(figsize=(10, 7))
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=classes, yticklabels=classes)
    plt.xlabel('Predicted')
    plt.ylabel('True')
    plt.show()

plot_confusion_matrix(cm, classes=list("ABCDEFGHIJ"))

# Calcular y mostrar la precisión y la medida F1 del modelo
accuracy = accuracy_score(test_labels, y_pred)
f1 = f1_score(test_labels, y_pred, average='weighted')

print(f"Final Accuracy: {accuracy * 100:.2f}%")
print(f"Final F1 Score: {f1:.2f}")

"""#Comentario sobre los resultados obtenidos

**Los resultados muestran que el desempeño de los clasificadores varía según el tipo de representación de características y el tipo de modelo Naïve Bayes utilizado.**

*   **MultinomialNB con TF-IDF:**

1.   Accuracy: **80.67%**
2.   F1 Score: **0.81**

Este modelo logra una **precisión bastante alta (la más alta) y un puntaje F1 sólido**. Es especialmente bueno en la clasificación de las clases C e I, con resultados F1 superiores al 90 %.
Esto se debe principalmente a la representación TF-IDF, que pondera la importancia de las palabras en los documentos. Sin embargo, para las clases A, B y E, la precisión es más baja, lo que indica que estas clases son más difíciles de distinguir.

**TF-IDF (Term Frequency-Inverse Document Frequency) transforma los textos en matrices de conteo ponderadas, que son discretas por naturaleza.**

**MultinomialNB está diseñado para manejar datos discretos como conteos de palabras, lo que lo hace una elección natural para la representación TF-IDF.**

TF-IDF pondera las palabras según su frecuencia en los documentos y su rareza en el corpus, lo que ayuda a identificar términos discriminativos para cada clase, mejorando la capacidad del clasificador para distinguir entre ellas.

*   **GaussianNB con TF-IDF:**

1.   Accuracy: **75.33 %**
2.   F1 Score: **0.76**

**El modelo GaussianNB con TF-IDF tiene un rendimiento inferior en comparación con MultinomialNB**. Aunque aún logra un puntaje F1 decente, especialmente para las clases I y J, las clases A, B y E muestran un rendimiento más deficiente comparado con el modelo anterior. Esto se puede deber a que GaussianNB asume que los datos siguen una distribución normal.

**Aunque GaussianNB está diseñado para datos continuos, se ha aplicado a datos discretos (TF-IDF) para la prueba.**

**La distribución gaussiana asumida por GaussianNB no se ajusta bien a los datos discretos generados por TF-IDF, pero aun así se quiso realizar la prueba para comparar resultados. Esto resultó en un rendimiento inferior en comparación con MultinomialNB.**

*   **MultinomialNB con *average model*:**

1.   Accuracy: **58.00 %**
2.   F1 Score: **0.56**

**El modelo MultinomialNB con *average model* muestra un rendimiento inferior en comparación con TF-IDF. La precisión y el puntaje F1 son más bajos en general, lo que indica que la representación promedio de los vectores de características no es tan efectiva como TF-IDF para este conjunto de datos.**

***Average model* utiliza vectores de características promedio continuos, obtenidos de embeddings de palabras.
MultinomialNB no es adecuado para datos continuos, ya que asume una distribución multinomial de datos discretos.**

**Aun así, se realizó la prueba para explorar su rendimiento, los resultados fueron inferiores debido a la incompatibilidad entre la naturaleza continua de los datos y la suposición discreta del modelo.**

*   **GaussianNB con *average model*:**

1.   Accuracy: **62.33 %**
2.   F1 Score: **0.61**


Similar al caso anterior, este modelo con *average model* también tiene un rendimiento inferior en comparación con su contraparte con TF-IDF.

Sí es cierto que mejora ligeramente respecto al MultinomialNB con *average model*, aún es superado por los modelos con TF-IDF.

La suposición de una distribución gaussiana por parte del modelo se adapta mejor a la naturaleza continua de los vectores de características promedio, resultando en un rendimiento relativamente mejor que MultinomialNB en este contexto.

Aunque la representación promedio de los vectores de características no se ajusta estrictamente a esta distribución, puede aproximarse mejor que una distribución multinomial, especialmente cuando los vectores de características promedio se calculan a partir de embeddings de palabras en espacios vectoriales de alta dimensionalidad.

**Esto implica que GaussianNB puede manejar mejor la variabilidad y la continuidad de los datos representados como vectores de características promedio, lo que resulta en un mejor rendimiento en comparación con MultinomialNB.**

Por tanto, se deduce que los resultados indican que la representación de características y el tipo de modelo Naïve Bayes tienen un impacto significativo en el rendimiento del clasificador.

**GaussianNB está diseñado para manejar datos continuos, lo que lo hace adecuado para los vectores de características promedio generados por el *average model*.**



###Conclusión final

**Aun así, en este caso, TF-IDF muestra un mejor rendimiento en comparación con la representación promedio de vectores de características, y MultinomialNB supera a GaussianNB en la mayoría de los casos, lo que sugiere que los datos pueden ajustarse mejor a una distribución multinomial en lugar de una distribución gaussiana, además de una representación TF-IDF.**
"""